{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5bc1adf",
   "metadata": {},
   "source": [
    "### Function\n",
    "- load dataStruct from NAS\n",
    "- saved it to \"D:\\Neural-Pipeline\\data\\processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfertonpz(subject=\"zarya\", date=\"20250523\"):\n",
    "\n",
    "    import numpy as np\n",
    "    import h5py\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    base_path = Path(r\"\\\\172.30.3.33\\homes\\fetschlab\\labMembers\\Yueh-Chen\") / subject / \"Neural data\"\n",
    "    file_name = f\"@{subject}_neurodata_cleaned.mat\"\n",
    "    matfile_path = base_path / file_name\n",
    "    output_dir = r\"D:\\Neural-Pipeline\\data\\processed\"\n",
    "\n",
    "    target_date = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "    print(f\"Target date: {target_date}\")\n",
    "\n",
    "    f = h5py.File(matfile_path, 'r')\n",
    "    dataStruct = f['dataStruct']\n",
    "\n",
    "    dates = dataStruct['date']\n",
    "    session_idx = None\n",
    "\n",
    "    for i in range(dates.shape[1]):\n",
    "        try:\n",
    "            date_ref = dates[0, i]\n",
    "            \n",
    "            try:\n",
    "                session_date = f[date_ref][()].decode('utf-16le').strip()\n",
    "            except:\n",
    "                try:\n",
    "                    session_date = f[date_ref][()].tobytes().decode('utf-16le').strip()\n",
    "                except:\n",
    "                    session_date = str(f[date_ref][()]).strip()\n",
    "            \n",
    "            if session_date == target_date:\n",
    "                session_idx = i\n",
    "                print(f\"Found matching session: {session_idx}\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading date from session {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if session_idx is None:\n",
    "        print(f\"No session found for date {target_date}\")\n",
    "\n",
    "\n",
    "    # Load data from the found session - fix the indexing\n",
    "    print(\"Loading data structures...\")\n",
    "    data_refs = dataStruct['data']\n",
    "    session_data_ref = data_refs[0, session_idx]\n",
    "    session_data = f[session_data_ref]\n",
    "\n",
    "    print(f\"Session data keys: {list(session_data.keys())}\")\n",
    "\n",
    "    # Process dots3DMP - it's already a group, no need for [0,0]\n",
    "    print(\"Processing dots3DMP...\")\n",
    "    dots3DMP = session_data['dots3DMP']\n",
    "\n",
    "    # Load events, unit, and spike rate references for dots3DMP\n",
    "    events = dots3DMP['events']\n",
    "    unit = dots3DMP['unit']\n",
    "    data_spkrate = dots3DMP['data_spkrate']\n",
    "   \n",
    "\n",
    "    print(\"Loading spike rate matrices for dots3DMP...\")\n",
    "    stimOn_spkrate = []\n",
    "    # saccOnset_spkrate = []\n",
    "    # postTargHold_spkrate = []\n",
    "\n",
    "    stimOn_refs = data_spkrate['stimOn']\n",
    "    # saccOnset_refs = data_spkrate['saccOnset'] \n",
    "    # postTargHold_refs = data_spkrate['postTargHold']\n",
    "\n",
    "    # print(f\"Loading {stimOn_refs.shape} spike rate cells...\")\n",
    "    # for i in range(stimOn_refs.shape[0]):\n",
    "    #     trial_stimOn = []\n",
    "    #     trial_saccOnset = []\n",
    "    #     trial_postTargHold = []\n",
    "        \n",
    "    #     for j in range(stimOn_refs.shape[1]):\n",
    "    #         if stimOn_refs[i, j] != 0:\n",
    "    #             trial_stimOn.append(f[stimOn_refs[i, j]][:])\n",
    "    #         else:\n",
    "    #             trial_stimOn.append(np.array([]))\n",
    "\n",
    "                \n",
    "    #         if saccOnset_refs[i, j] != 0:\n",
    "    #             trial_saccOnset.append(f[saccOnset_refs[i, j]][:])\n",
    "    #         else:\n",
    "    #             trial_saccOnset.append(np.array([]))\n",
    "                \n",
    "    #         if postTargHold_refs[i, j] != 0:\n",
    "    #             trial_postTargHold.append(f[postTargHold_refs[i, j]][:])\n",
    "    #         else:\n",
    "    #             trial_postTargHold.append(np.array([]))\n",
    "        \n",
    "        # stimOn_spkrate.append(trial_stimOn)\n",
    "    #     saccOnset_spkrate.append(trial_saccOnset)\n",
    "    #     postTargHold_spkrate.append(trial_postTargHold)\n",
    "        \n",
    "    #     if i % 10 == 0:\n",
    "    #         print(f\"  Loaded {i}/{stimOn_refs.shape[0]} units\")\n",
    "\n",
    "    # print(\"Loading behavioral data for dots3DMP...\")\n",
    "    # choice = events['choice']\n",
    "    # PDW = events['PDW']\n",
    "    # modality = events['modality']\n",
    "    # headingInd = events['headingInd']\n",
    "    # coherenceInd = events['coherenceInd']\n",
    "    # goodtrial = events['goodtrial']\n",
    "    # deltaInd = events['deltaInd']\n",
    "    # correct = events['correct']\n",
    "    # oneTargChoice = events['oneTargChoice']\n",
    "    # oneTargConf = events['oneTargConf']\n",
    "    # heading = events['heading']\n",
    "    # coherence = events['coherence']\n",
    "    # delta = events['delta']\n",
    "    # RT = events['RT']\n",
    "\n",
    "    print(\"Loading unit data...\")\n",
    "    depth = unit['depth']\n",
    "    cluster_id = unit['cluster_id']\n",
    "\n",
    "    cluster_group_data = unit['cluster_group']\n",
    "    group_ref = cluster_group_data['group']\n",
    "\n",
    "\n",
    "    cluster_group = []\n",
    "    for i in range(group_ref.shape[1]):  \n",
    "        # Get the character codes for this unit (column i)\n",
    "        char_codes = group_ref[:, i]\n",
    "        \n",
    "        # Convert to string\n",
    "        try:\n",
    "            # Convert uint16 array to string\n",
    "            group_str = ''.join([chr(code) for code in char_codes if code != 0]).strip()\n",
    "            cluster_group.append(group_str)\n",
    "        except Exception as e:\n",
    "            print(f\"Error at unit {i}: {e}\")\n",
    "            cluster_group.append(\"unknown\")\n",
    "\n",
    "    cluster_group = np.array(cluster_group)\n",
    "\n",
    "    # # Save dots3DMP\n",
    "    # output_file_dots3DMP = os.path.join(output_dir, f\"{subject}{date}dots3DMP_processed.npz\")\n",
    "    # print(f\"Saving dots3DMP to {output_file_dots3DMP}...\")\n",
    "\n",
    "    # np.savez_compressed(output_file_dots3DMP,\n",
    "    #     stimOn_spkrate=stimOn_spkrate,\n",
    "    #     saccOnset_spkrate=saccOnset_spkrate, \n",
    "    #     postTargHold_spkrate=postTargHold_spkrate,\n",
    "    #     choice=choice,\n",
    "    #     PDW=PDW,\n",
    "    #     modality=modality,\n",
    "    #     headingInd=headingInd,\n",
    "    #     coherenceInd=coherenceInd,\n",
    "    #     goodtrial=goodtrial,\n",
    "    #     deltaInd=deltaInd,\n",
    "    #     correct=correct,\n",
    "    #     oneTargChoice=oneTargChoice,\n",
    "    #     oneTargConf=oneTargConf,\n",
    "    #     heading=heading,\n",
    "    #     coherence=coherence,\n",
    "    #     delta=delta,\n",
    "    #     RT=RT,\n",
    "    #     depth=depth,\n",
    "    #     cluster_id=cluster_id,\n",
    "    #     cluster_group=cluster_group,\n",
    "    #     subject=subject,\n",
    "    #     date=date,\n",
    "    #     session_idx=session_idx\n",
    "    # )\n",
    "\n",
    "    # Process dots3DMPtuning\n",
    "    print(\"Processing dots3DMPtuning...\")\n",
    "    dots3DMPtuning = session_data['dots3DMPtuning']\n",
    "\n",
    "    events_tuning = dots3DMPtuning['events']\n",
    "    data_spkrate_tuning = dots3DMPtuning['data_spkrate']\n",
    "\n",
    "    print(\"Loading spike rate data for dots3DMPtuning...\")\n",
    "    spkrate_refs = data_spkrate_tuning\n",
    "\n",
    "    # First pass: determine dimensions\n",
    "    max_time_bins = 0\n",
    "    for i in range(spkrate_refs.shape[0]):\n",
    "        for j in range(spkrate_refs.shape[1]):\n",
    "            ref = spkrate_refs[i, j]\n",
    "            if ref != 0:\n",
    "                data = f[ref][:]\n",
    "                max_time_bins = max(max_time_bins, len(data))\n",
    "     \n",
    "\n",
    "    # Create array in format [event, unit, timeaxis, 1]\n",
    "    n_events = spkrate_refs.shape[1] \n",
    "    n_units = spkrate_refs.shape[0]   \n",
    "    spkrate = np.zeros((n_events, n_units, max_time_bins, 1))\n",
    "\n",
    "    for i in range(n_units):\n",
    "        for j in range(n_events):\n",
    "            ref = spkrate_refs[i, j]\n",
    "            if ref != 0:\n",
    "                data = f[ref][:]\n",
    "                data = np.squeeze(data)\n",
    "                spkrate[j, i, :, 0] = data\n",
    "            else:\n",
    "                spkrate[j, i, :, 0] = np.nan\n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Loaded {i}/{n_units} units\")\n",
    "\n",
    "    print(f\"Final spkrate shape [event, unit, timeaxis, 1]: {spkrate.shape}\")\n",
    "\n",
    "    print(\"Loading behavioral data for dots3DMPtuning...\")\n",
    "    goodtrial_tuning = events_tuning['goodtrial']\n",
    "    headingInd_tuning = events_tuning['headingInd']\n",
    "    modality_tuning = events_tuning['modality']\n",
    "    coherenceInd_tuning = events_tuning['coherenceInd']\n",
    "    deltaInd_tuning = events_tuning['deltaInd']\n",
    "\n",
    "    # Save dots3DMPtuning\n",
    "    output_file_tuning = os.path.join(output_dir, f\"{subject}{date}dots3DMPtuning_processed.npz\")\n",
    "    print(f\"Saving dots3DMPtuning to {output_file_tuning}...\")\n",
    "\n",
    "    np.savez_compressed(output_file_tuning,\n",
    "        spkrate=spkrate,\n",
    "        goodtrial=goodtrial_tuning,\n",
    "        headingInd=headingInd_tuning,\n",
    "        modality=modality_tuning,\n",
    "        coherenceInd=coherenceInd_tuning,\n",
    "        deltaInd=deltaInd_tuning,\n",
    "        depth=depth,\n",
    "        cluster_id=cluster_id,\n",
    "        cluster_group=cluster_group,\n",
    "        subject=subject,\n",
    "        date=date,\n",
    "        session_idx=session_idx\n",
    "    )\n",
    "\n",
    "    print(\"Both files saved successfully!\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d45807",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1aeb133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target date: 2025-05-23\n",
      "Found matching session: 19\n",
      "Loading data structures...\n",
      "Session data keys: ['dots3DMP', 'dots3DMPtuning']\n",
      "Processing dots3DMP...\n",
      "Loading spike rate matrices for dots3DMP...\n",
      "Loading unit data...\n",
      "Processing dots3DMPtuning...\n",
      "Loading spike rate data for dots3DMPtuning...\n",
      "Final spkrate shape [event, unit, timeaxis, 1]: (165, 722, 134, 1)\n",
      "Loading behavioral data for dots3DMPtuning...\n",
      "Saving dots3DMPtuning to D:\\Neural-Pipeline\\data\\processed\\zarya20250523dots3DMPtuning_processed.npz...\n",
      "Both files saved successfully!\n",
      "Target date: 2025-06-02\n",
      "Found matching session: 20\n",
      "Loading data structures...\n",
      "Session data keys: ['dots3DMP', 'dots3DMPtuning']\n",
      "Processing dots3DMP...\n",
      "Loading spike rate matrices for dots3DMP...\n",
      "Loading unit data...\n",
      "Processing dots3DMPtuning...\n",
      "Loading spike rate data for dots3DMPtuning...\n",
      "Final spkrate shape [event, unit, timeaxis, 1]: (162, 528, 134, 1)\n",
      "Loading behavioral data for dots3DMPtuning...\n",
      "Saving dots3DMPtuning to D:\\Neural-Pipeline\\data\\processed\\zarya20250602dots3DMPtuning_processed.npz...\n",
      "Both files saved successfully!\n",
      "Target date: 2025-07-02\n",
      "Found matching session: 21\n",
      "Loading data structures...\n",
      "Session data keys: ['dots3DMP', 'dots3DMPtuning']\n",
      "Processing dots3DMP...\n",
      "Loading spike rate matrices for dots3DMP...\n",
      "Loading unit data...\n",
      "Processing dots3DMPtuning...\n",
      "Loading spike rate data for dots3DMPtuning...\n",
      "Final spkrate shape [event, unit, timeaxis, 1]: (305, 773, 134, 1)\n",
      "Loading behavioral data for dots3DMPtuning...\n",
      "Saving dots3DMPtuning to D:\\Neural-Pipeline\\data\\processed\\zarya20250702dots3DMPtuning_processed.npz...\n",
      "Both files saved successfully!\n",
      "Target date: 2025-07-10\n",
      "Found matching session: 22\n",
      "Loading data structures...\n",
      "Session data keys: ['dots3DMP', 'dots3DMPtuning']\n",
      "Processing dots3DMP...\n",
      "Loading spike rate matrices for dots3DMP...\n",
      "Loading unit data...\n",
      "Processing dots3DMPtuning...\n",
      "Loading spike rate data for dots3DMPtuning...\n",
      "Final spkrate shape [event, unit, timeaxis, 1]: (154, 617, 134, 1)\n",
      "Loading behavioral data for dots3DMPtuning...\n",
      "Saving dots3DMPtuning to D:\\Neural-Pipeline\\data\\processed\\zarya20250710dots3DMPtuning_processed.npz...\n",
      "Both files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "subject = \"zarya\"\n",
    "dates = [\"20250523\", \"20250602\", \"20250702\", \"20250710\"]\n",
    "\n",
    "for idx, date in enumerate(dates):  \n",
    "    transfertonpz(subject, date)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
