{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e3a286-0b1f-44cf-896c-2d74fd299aea",
   "metadata": {},
   "source": [
    "### todo\n",
    "- \"newtrial_frame\", we might not need it in the future\n",
    "- save name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025615e7-f05e-49a2-b73e-4e03b375016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from pathlib import Path\n",
    "# from kilosort.io import load_ops\n",
    "\n",
    "date = 20250710\n",
    "\n",
    "# Define Path and Load Files\n",
    "results_dir = Path(r'D:\\Neural-Pipeline\\data\\20250602\\kilosort4_phy')\n",
    "# APtimestamps = np.load(r\"D:\\20250313\\2025-03-13_15-09-41\\Record Node 101\\experiment1\\recording1\\continuous\\Neuropix-PXI-100.ProbeA-AP\\timestamps.npy\")\n",
    "# save_path = r'D:\\20250313\\zarya_20250313__bankAB_unit.mat'\n",
    "\n",
    "# spike_clusters = np.load(results_dir / 'spike_clusters.npy')\n",
    "spike_times = np.load(results_dir / 'spike_times.npy')\n",
    "spike_pos = np.load(results_dir / 'spike_positions.npy')\n",
    "channel_positions = np.load(results_dir / 'channel_positions.npy')\n",
    "\n",
    "channel_map =  np.load(results_dir / 'channel_map.npy')\n",
    "templates =  np.load(results_dir / 'templates.npy')\n",
    "\n",
    "cluster_group = pd.read_csv(results_dir / 'cluster_info.tsv', sep='\\t')\n",
    "# good_count = (cluster_group[\"group\"] == \"good\").sum()\n",
    "# test = cluster_group[\"depth\"][0]\n",
    "# print(f\"Number of 'good' clusters: {good_count}\")\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee838eba",
   "metadata": {},
   "source": [
    "### Report number of unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b4e6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Kilosort Labels (KSLabel) ===\n",
      "KSLabel\n",
      "good    506\n",
      "mua     411\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Phy Curated Labels (group) ===\n",
      "group\n",
      "mua      429\n",
      "noise    216\n",
      "good     176\n",
      "NaN        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "phy = True\n",
    "\n",
    "phy_dir = Path(r'D:\\Neural-Pipeline\\data\\20250417\\kilosort4_phy')\n",
    "kilo_dir = Path(r'D:\\Neural-Pipeline\\data\\20250417\\kilosort4')\n",
    "cluster_group = pd.read_csv(phy_dir / 'cluster_info.tsv', sep='\\t')\n",
    "kilo_cluster = pd.read_csv(kilo_dir / 'cluster_KSLabel.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "# Count KSLabel (Kilosort output)\n",
    "kslabel_counts = kilo_cluster['KSLabel'].value_counts(dropna=False)\n",
    "\n",
    "# Count group (Phy manual curation)\n",
    "if phy:\n",
    "    group_counts = cluster_group['group'].value_counts(dropna=False)\n",
    "\n",
    "# Report both\n",
    "print(\"=== Kilosort Labels (KSLabel) ===\")\n",
    "print(kslabel_counts)\n",
    "if phy: \n",
    "    print(\"\\n=== Phy Curated Labels (group) ===\")\n",
    "    print(group_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08974002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster_id  Amplitude  ContamPct KSLabel          amp   ch   depth  \\\n",
      "0             0       39.8        0.0    good  1760.941895    0     0.0   \n",
      "1             1       21.7        0.0    good   976.867065    4    40.0   \n",
      "2             2       11.0        6.2    good   517.755310    2    20.0   \n",
      "3             3       18.1        0.0     mua   676.689575    2    20.0   \n",
      "4             4       26.7        0.0    good  1274.200806    2    20.0   \n",
      "..          ...        ...        ...     ...          ...  ...     ...   \n",
      "884         884        9.3       16.0    good   267.885773  379  7620.0   \n",
      "885         885       10.4       46.9     mua   349.544800  379  7620.0   \n",
      "886         886       10.0       14.7    good   316.992188  383  7660.0   \n",
      "887         887        9.5       33.3     mua   328.081604  381  7640.0   \n",
      "888         888        9.3       29.5     mua   271.145691  381  7640.0   \n",
      "\n",
      "           fr  group  n_spikes   sh  \n",
      "0    0.024184    NaN       358  1.0  \n",
      "1    0.012903    NaN       191  1.0  \n",
      "2    0.256097    NaN      3791  1.0  \n",
      "3    0.010268    NaN       152  1.0  \n",
      "4    0.186179    NaN      2756  1.0  \n",
      "..        ...    ...       ...  ...  \n",
      "884  2.606705    NaN     38587  1.0  \n",
      "885  6.651160    NaN     98457  1.0  \n",
      "886  1.650276    NaN     24429  1.0  \n",
      "887  1.049451    NaN     15535  1.0  \n",
      "888  2.302442    NaN     34083  1.0  \n",
      "\n",
      "[889 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cluster_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eca0cd-56c7-4761-9fdd-27ca08e19326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chan_best = (templates**2).sum(axis=1).argmax(axis=-1)\n",
    "chan_best = channel_map[chan_best]\n",
    "template_amplitudes = ((templates**2).sum(axis=(-2,-1))**0.5)\n",
    "uniq_spike_clusters = np.unique(spike_clusters)\n",
    "spike_counts = np.unique(spike_clusters, return_counts=True)[1]\n",
    "channel_y_positions = channel_positions[:, 1]\n",
    "newtrial_frame = np.where(np.diff(APtimestamps) < -1) [0]\n",
    "print(newtrial_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0978f5da-83e1-46dc-8257-93d0c05dd313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved at 'D:\\20250313\\zarya_20250313__bankAB_unit.mat'.\n"
     ]
    }
   ],
   "source": [
    "## 20250313 version\n",
    "uniq_spike_clusters = np.unique(spike_clusters)\n",
    "depth = np.zeros(len(uniq_spike_clusters))\n",
    "group = np.zeros(len(uniq_spike_clusters))\n",
    "cluster_id = np.zeros(len(uniq_spike_clusters))\n",
    "ch = np.zeros(len(uniq_spike_clusters))\n",
    "spiketimes = {i: [] for i in range(len(uniq_spike_clusters))}\n",
    "\n",
    "\n",
    "for i, cluster in enumerate(uniq_spike_clusters):\n",
    "    idx = np.where(spike_clusters == cluster)\n",
    "    unit_kilo_frame  = spike_times[idx]\n",
    "\n",
    "    unit_spike_time = APtimestamps[unit_kilo_frame]\n",
    "    \n",
    "    cluster_id[i] = cluster\n",
    "    spiketimes[i].extend(unit_spike_time)\n",
    "    \n",
    "    depth[i] = cluster_group[\"depth\"][i]\n",
    "    group[i] = int(cluster_group.loc[cluster_group[\"cluster_id\"] == cluster, \"group\"].values[0] == \"good\")\n",
    "\n",
    "spiketimes = np.array([spiketimes[i] for i in range(len(uniq_spike_clusters))], dtype=object)\n",
    "units = {\n",
    "    'depth': depth,\n",
    "    'cluster_id': cluster_id,\n",
    "    'groups': group,\n",
    "    'spiketimes': spiketimes\n",
    "    'cluster_group': cluster_group\n",
    "}\n",
    "\n",
    "scipy.io.savemat(save_path, {'units': units})\n",
    "\n",
    "print(f\"Data saved at '{save_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6077a66d-6dac-4ebd-bb82-37e03e0dbe27",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2117,) (0,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m idx \u001b[38;5;241m=\u001b[39m spike_clusters \u001b[38;5;241m==\u001b[39m cluster\n\u001b[0;32m     11\u001b[0m unit_kilo_frame  \u001b[38;5;241m=\u001b[39m spike_times[idx]\n\u001b[1;32m---> 12\u001b[0m trial_frame \u001b[38;5;241m=\u001b[39m (\u001b[43munit_kilo_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnewtrial_frame\u001b[49m)\n\u001b[0;32m     13\u001b[0m unit_kilo_frame \u001b[38;5;241m=\u001b[39m unit_kilo_frame[trial_frame]\n\u001b[0;32m     15\u001b[0m unit_spike_time \u001b[38;5;241m=\u001b[39m APtimestamps[unit_kilo_frame]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2117,) (0,) "
     ]
    }
   ],
   "source": [
    "## 20241220 version\n",
    "\n",
    "depth = np.zeros(len(uniq_spike_clusters))\n",
    "group = np.zeros(len(uniq_spike_clusters))\n",
    "cluster_id = np.zeros(len(uniq_spike_clusters))\n",
    "ch = np.zeros(len(uniq_spike_clusters))\n",
    "spiketimes = {i: [] for i in range(len(uniq_spike_clusters))}\n",
    "\n",
    "for i, cluster in enumerate(uniq_spike_clusters):\n",
    "    idx = spike_clusters == cluster\n",
    "    unit_kilo_frame  = spike_times[idx]\n",
    "    # trial_frame = (unit_kilo_frame >= newtrial_frame)\n",
    "    # unit_kilo_frame = unit_kilo_frame[trial_frame]\n",
    "\n",
    "    unit_spike_time = APtimestamps[unit_kilo_frame]\n",
    "    \n",
    "    cluster_id[i] = cluster\n",
    "    spiketimes[i].extend(unit_spike_time)\n",
    "    \n",
    "    chbest = chan_best[i]\n",
    "    ch[i] = chbest\n",
    "    depth[i] = channel_y_positions[chbest]\n",
    "    group[i] = \n",
    "\n",
    "spiketimes = np.array([spiketimes[i] for i in range(len(uniq_spike_clusters))], dtype=object)\n",
    "units = {\n",
    "    'depth': depth,\n",
    "    'ch': ch,\n",
    "    'cluster_id': cluster_id,\n",
    "    'spiketimes': spiketimes\n",
    "}\n",
    "\n",
    "scipy.io.savemat(save_path, {'units': units})\n",
    "\n",
    "print(f\"Data saved at '{save_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
